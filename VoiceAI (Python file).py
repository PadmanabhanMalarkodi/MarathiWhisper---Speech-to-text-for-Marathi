# -*- coding: utf-8 -*-
"""VoiceAI.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dsTeut_P8zHAg5qli8DYm2d_boSxba6_
"""


# Install the required libraries
! pip3 install transformers
! pip install jiwer
! pip3 install datasets

import torch
from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline
from datasets import load_dataset


device = "cuda:0" if torch.cuda.is_available() else "cpu"
torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32

"""
Reason for choosing OpenAI Whisper v3 Large model for speech-to-text task can be based on several considerations:

1. The Whisper v3 Large model is designed to deliver high performance in automatic speech recognition (ASR) tasks. 
2. It has been trained on a large amount of diverse multilingual data, making it well-suited for capturing various accents, languages, and speaking styles.
3. The availability of pretrained weights for the Whisper v3 Large model means that you can leverage the knowledge learned during the pretraining phase, saving time and computational resources during the fine-tuning process.
"""
model_id = "openai/whisper-large-v3"

model = AutoModelForSpeechSeq2Seq.from_pretrained(
    model_id, torch_dtype=torch_dtype, use_safetensors=True
)

model.to(device)

processor = AutoProcessor.from_pretrained(model_id)

pipe = pipeline(
    "automatic-speech-recognition",
    model=model,
    tokenizer=processor.tokenizer,
    feature_extractor=processor.feature_extractor,
    max_new_tokens=128,
    chunk_length_s=30,
    batch_size=16,
    return_timestamps=True,
    torch_dtype=torch_dtype,
    device=device,
)

dataset = load_dataset("distil-whisper/librispeech_long", "clean", split="validation")
sample = dataset[0]["audio"]

result = pipe(sample)
print(result["text"])


# Code for transcribing a single audio text

sample = '/content/common_voice_mr_27591986.wav'
result = pipe(sample)
print(result["text"])


reference = "या पानास लेखाचे स्वरूप यायला हवे"

def calculate_wer(reference, hypothesis):
	ref_words = reference.split()
	hyp_words = hypothesis.split()
	# Counting the number of substitutions, deletions, and insertions
	substitutions = sum(1 for ref, hyp in zip(ref_words, hyp_words) if ref != hyp)
	deletions = len(ref_words) - len(hyp_words)
	insertions = len(hyp_words) - len(ref_words)
	# Total number of words in the reference text
	total_words = len(ref_words)
	# Calculating the Word Error Rate (WER)
	wer = (substitutions + deletions + insertions) / total_words
	return wer

print(calculate_wer(reference,result["text"]))

# Code for transcribing multiple audio file

sample = '/content/common_voice_mr_27591986.wav'
result = pipe(sample)
print(result["text"])

from google.colab import drive
drive.mount('/content/drive')

# Note: Sample_voice_test folder contains few audio samples which were taken from the common_voice_test

import os
folder_path = "/content/drive/MyDrive/Sample_voice_test"
for filename in os.listdir(folder_path):
    if filename.endswith((".wav", ".mp3", ".flac")):
        audio_path = os.path.join(folder_path, filename)
        sample = audio_path
        result = pipe(sample)
        print(f"Transcription for {filename}: {result['text']}")

import os
folder_path = "/content/drive/MyDrive/Sample_voice_test"  

transcriptions = []

for filename in os.listdir(folder_path):
    if filename.endswith((".wav", ".mp3", ".flac")):
        audio_path = os.path.join(folder_path, filename)
        sample = audio_path
        result = pipe(sample)
        transcription = result["text"]
        transcriptions.append(transcription)
print(transcriptions)

hypothesis_texts = [
    "संत ज्ञानेश्वरांच्या सातव्या जन्मशताब्दीनिमित्त त्यांनी सर्वप्रथम मोगरा फुलला या कादंबरीचे अभिवाचन केले होते",
    "सत्यवती अंबालिकेला व्यासांना बघितल्यावर डोळे मिटू नकोस असे सांगते",
    "पंजाब एक कृषि प्रधान राज्य आहे"
    "या पानास लेखाचे स्वरूप यायला हवे"
]

"""
Evalation metrics:

WER (Word Error Rate) is a common metric for evaluating the accuracy of speech-to-text models.
It calculates the difference between the reference and hypothesis transcriptions in terms of words.
"""

#Implementation of WER in Python

for reference, hypothesis in zip(transcriptions, hypothesis_texts):
  ref_words = reference.split()
  hyp_words = hypothesis.split()
  # Counting the number of substitutions, deletions, and insertions
  substitutions = sum(1 for ref, hyp in zip(ref_words, hyp_words) if ref != hyp)
  deletions = len(ref_words) - len(hyp_words)
  insertions = len(hyp_words) - len(ref_words)
  # Total number of words in the reference text
  total_words = len(ref_words)
  # Calculating the Word Error Rate (WER)
  wer = (substitutions + deletions + insertions) / total_words
  print(wer)

# WER with JiWER Library  

from jiwer import wer

# Calculate WER for each pair of reference and hypothesis
for reference, hypothesis in zip(transcriptions, hypothesis_texts):
    error_rate = wer(reference, hypothesis)
    print(f"WER: {error_rate:.2%}")    # WER in terms of percentage